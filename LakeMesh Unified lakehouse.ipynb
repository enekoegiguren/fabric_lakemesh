{"cells":[{"cell_type":"markdown","source":["# **Fabric Lakehouse Consolidation Tool**\n","\n","\n","###### This notebook provides an automated solution for creating and managing consolidated lakehouses in Microsoft Fabric.\n","###### It allows you to create a unified lakehouse with shortcuts to multiple source lakehouses, organized by schemas, with intelligent filtering and refresh capabilities.\n","\n","--- \n","## What this tool does\n","\n","###### This tool automates the creation of a **consolidated lakehouse** that acts as a centralized view of multiple source lakehouses (e.g., Bronze, Silver, Gold layers in a medallion architecture). Instead of copying data, it creates **shortcuts** (symbolic links) to tables in source lakehouses, organizing them into schemas for easy navigation.\n","\n","---"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5c0c1334-6ab0-4a71-bac8-d18578bfbc62"},{"cell_type":"markdown","source":["# Use the tool"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"aa735966-6a24-461a-b9b9-73d4448fdb15"},{"cell_type":"markdown","source":["## Prerequisites"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"40912ae5-7232-4c74-8f1a-4fd409b6e75f"},{"cell_type":"code","source":["#### PACKAGES\n","\n","import requests\n","import json\n","from notebookutils import mssparkutils\n","import time\n","from typing import List, Dict, Optional"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"1bfba26f-2861-45c5-b30b-1a3ba2850f1c","normalized_state":"finished","queued_time":"2026-01-15T20:26:44.9468439Z","session_start_time":null,"execution_start_time":"2026-01-15T20:26:44.9479292Z","execution_finish_time":"2026-01-15T20:26:45.2941631Z","parent_msg_id":"fa50f0e2-2893-4c91-9c0e-4a17d770a4ea"},"text/plain":"StatementMeta(, 1bfba26f-2861-45c5-b30b-1a3ba2850f1c, 4, Finished, Available, Finished)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"451bc04b-7b50-4503-b853-3ae140f5ab4a"},{"cell_type":"code","source":["#### TOKEN GENERATION\n","token = mssparkutils.credentials.getToken(\"pbi\")\n","\n","headers = {\n","    \"Authorization\": f\"Bearer {token}\",\n","    \"Content-Type\": \"application/json\"\n","}\n","\n","base_url = \"https://api.fabric.microsoft.com/v1\"\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f1061232-1f0b-4240-aabb-f59f25aae973"},{"cell_type":"markdown","source":["## Functions"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"15ff7db9-d6d4-400f-9a94-0a2fd72db031"},{"cell_type":"code","source":["def create_lakehouse(workspace_id: str, lakehouse_name: str) -> Optional[str]:\n","    \"\"\"Creates a new lakehouse\"\"\"\n","    url = f\"{base_url}/workspaces/{workspace_id}/lakehouses\"\n","    payload = {\n","        \"displayName\": lakehouse_name\n","    }\n","    response = requests.post(url, headers=headers, json=payload)\n","    if response.status_code in [200, 201]:\n","        return response.json()[\"id\"]\n","    else:\n","        print(f\"Error creating lakehouse: {response.status_code} - {response.text}\")\n","        return None\n","\n","def get_lakehouse_tables(workspace_id: str, lakehouse_id: str) -> List[Dict]:\n","    \"\"\"Gets all tables from a lakehouse\"\"\"\n","    url = f\"{base_url}/workspaces/{workspace_id}/lakehouses/{lakehouse_id}/tables\"\n","    response = requests.get(url, headers=headers)\n","    if response.status_code == 200:\n","        return response.json().get(\"data\", [])\n","    else:\n","        print(f\"Error getting tables: {response.status_code} - {response.text}\")\n","        return []\n","\n","def get_existing_shortcuts(workspace_id: str, lakehouse_id: str, schema_name: str) -> List[str]:\n","    \"\"\"Gets existing shortcuts in a specific schema\"\"\"\n","    url = f\"{base_url}/workspaces/{workspace_id}/items/{lakehouse_id}/shortcuts\"\n","    response = requests.get(url, headers=headers)\n","    \n","    existing_shortcuts = []\n","    if response.status_code == 200:\n","        shortcuts = response.json().get(\"value\", [])\n","        # Filter shortcuts that belong to this schema\n","        for shortcut in shortcuts:\n","            if shortcut.get(\"path\", \"\").startswith(f\"Tables/{schema_name}/\"):\n","                existing_shortcuts.append(shortcut.get(\"name\"))\n","    \n","    return existing_shortcuts\n","\n","def delete_shortcut(workspace_id: str, lakehouse_id: str, shortcut_path: str, shortcut_name: str) -> bool:\n","    \"\"\"Deletes a shortcut\"\"\"\n","    url = f\"{base_url}/workspaces/{workspace_id}/items/{lakehouse_id}/shortcuts/{shortcut_path}/{shortcut_name}\"\n","    response = requests.delete(url, headers=headers)\n","    return response.status_code in [200, 204]\n","\n","def create_shortcut(target_workspace_id: str, target_lakehouse_id: str, shortcut_path: str, \n","                   shortcut_name: str, source_workspace_id: str, source_lakehouse_id: str, \n","                   source_path: str) -> tuple[bool, str]:\n","    \"\"\"Creates a shortcut according to Microsoft official documentation\"\"\"\n","    url = f\"{base_url}/workspaces/{target_workspace_id}/items/{target_lakehouse_id}/shortcuts\"\n","    \n","    payload = {\n","        \"path\": shortcut_path,\n","        \"name\": shortcut_name,\n","        \"target\": {\n","            \"oneLake\": {\n","                \"workspaceId\": source_workspace_id,\n","                \"itemId\": source_lakehouse_id,\n","                \"path\": source_path\n","            }\n","        }\n","    }\n","    \n","    response = requests.post(url, headers=headers, json=payload)\n","    \n","    if response.status_code in [200, 201]:\n","        return True, \"Success\"\n","    else:\n","        return False, f\"{response.status_code} - {response.text}\"\n","\n","def verify_lakehouse(workspace_id: str, lakehouse_id: str) -> bool:\n","    \"\"\"Verifies that a lakehouse exists and is accessible\"\"\"\n","    url = f\"{base_url}/workspaces/{workspace_id}/lakehouses/{lakehouse_id}\"\n","    response = requests.get(url, headers=headers)\n","    return response.status_code == 200\n","\n","def filter_tables(tables: List[Dict], table_filter: List[str]) -> List[Dict]:\n","    \"\"\"Filters tables based on the provided filter list\"\"\"\n","    if not table_filter:  # Empty list means all tables\n","        return tables\n","    \n","    # Filter tables that match the filter list (case-insensitive)\n","    filter_lower = [t.lower() for t in table_filter]\n","    filtered = [table for table in tables if table[\"name\"].lower() in filter_lower]\n","    \n","    return filtered\n","\n","def process_source(target_workspace_id: str, target_lakehouse_id: str, \n","                  source_name: str, source_config: Dict, \n","                  refresh_mode: bool = False) -> Dict:\n","    \"\"\"\n","    Processes a single source to create shortcuts\n","    \n","    Args:\n","        refresh_mode: If True, only creates shortcuts for new tables\n","    \"\"\"\n","    schema_name = source_config[\"schema_name\"]\n","    source_workspace_id = source_config[\"workspace_id\"]\n","    source_lakehouse_id = source_config[\"lakehouse_id\"]\n","    table_filter = source_config.get(\"table_filter\", [])\n","    \n","    print(f\"\\n{'='*70}\")\n","    print(f\"[SOURCE] {source_name.upper()}\")\n","    print(f\"{'='*70}\")\n","    print(f\"  Workspace ID: {source_workspace_id}\")\n","    print(f\"  Lakehouse ID: {source_lakehouse_id}\")\n","    print(f\"  Target Schema: {schema_name}\")\n","    if table_filter:\n","        print(f\"  Table Filter: {', '.join(table_filter)}\")\n","    else:\n","        print(f\"  Table Filter: All tables\")\n","    print(f\"  Mode: {'REFRESH' if refresh_mode else 'INITIAL SETUP'}\")\n","    \n","    # Verify access to source lakehouse\n","    print(f\"\\n  üîç Verifying access to source lakehouse...\")\n","    if not verify_lakehouse(source_workspace_id, source_lakehouse_id):\n","        print(f\"  ‚ùå Cannot access lakehouse {source_name}\")\n","        print(f\"     Check permissions and verify the ID is correct\")\n","        return {\"total\": 0, \"success\": 0, \"failed\": 0, \"skipped\": 0}\n","    print(f\"  ‚úÖ Lakehouse accessible\")\n","    \n","    # Get existing shortcuts if in refresh mode\n","    existing_shortcuts = []\n","    if refresh_mode:\n","        print(f\"\\n  üìã Getting existing shortcuts...\")\n","        existing_shortcuts = get_existing_shortcuts(target_workspace_id, target_lakehouse_id, schema_name)\n","        print(f\"  ‚ÑπÔ∏è  Found {len(existing_shortcuts)} existing shortcuts\")\n","    \n","    # Get tables\n","    print(f\"\\n  üìã Getting table list...\")\n","    all_tables = get_lakehouse_tables(source_workspace_id, source_lakehouse_id)\n","    \n","    if not all_tables:\n","        print(f\"  ‚ö†Ô∏è  No tables found in {source_name}\")\n","        return {\"total\": 0, \"success\": 0, \"failed\": 0, \"skipped\": 0}\n","    \n","    print(f\"  ‚úÖ {len(all_tables)} tables found\")\n","    \n","    # Apply filter\n","    tables = filter_tables(all_tables, table_filter)\n","    \n","    if table_filter:\n","        print(f\"  üîç After applying filter: {len(tables)} tables\")\n","        if len(tables) < len(all_tables):\n","            excluded = len(all_tables) - len(tables)\n","            print(f\"     ({excluded} tables excluded by filter)\")\n","    \n","    if not tables:\n","        print(f\"  ‚ö†Ô∏è  No tables match the filter criteria\")\n","        return {\"total\": 0, \"success\": 0, \"failed\": 0, \"skipped\": 0}\n","    \n","    # Create shortcuts\n","    print(f\"\\n  üîó Creating shortcuts...\")\n","    success_count = 0\n","    failed_count = 0\n","    skipped_count = 0\n","    failed_tables = []\n","    \n","    for i, table in enumerate(tables, 1):\n","        table_name = table[\"name\"]\n","        \n","        # Skip if shortcut already exists (refresh mode)\n","        if refresh_mode and table_name in existing_shortcuts:\n","            print(f\"     [{i:3d}/{len(tables)}] {table_name}... ‚è≠Ô∏è  (already exists)\")\n","            skipped_count += 1\n","            continue\n","        \n","        # Path in target lakehouse: Tables/schema_name\n","        shortcut_path = f\"Tables/{schema_name}\"\n","        \n","        # Path in source lakehouse: Tables/table_name\n","        source_path = f\"Tables/{table_name}\"\n","        \n","        print(f\"     [{i:3d}/{len(tables)}] {table_name}...\", end=\" \")\n","        \n","        success, message = create_shortcut(\n","            target_workspace_id=target_workspace_id,\n","            target_lakehouse_id=target_lakehouse_id,\n","            shortcut_path=shortcut_path,\n","            shortcut_name=table_name,\n","            source_workspace_id=source_workspace_id,\n","            source_lakehouse_id=source_lakehouse_id,\n","            source_path=source_path\n","        )\n","        \n","        if success:\n","            print(\"‚úÖ\")\n","            success_count += 1\n","        else:\n","            print(f\"‚ùå\")\n","            print(f\"          Error: {message}\")\n","            failed_tables.append(table_name)\n","            failed_count += 1\n","        \n","        # Small pause to avoid rate limiting\n","        time.sleep(0.5)\n","    \n","    # Source summary\n","    print(f\"\\n  üìä Summary for {source_name}:\")\n","    print(f\"     ‚úÖ Successful: {success_count}\")\n","    if refresh_mode and skipped_count > 0:\n","        print(f\"     ‚è≠Ô∏è  Skipped (already exist): {skipped_count}\")\n","    print(f\"     ‚ùå Failed: {failed_count}\")\n","    \n","    if failed_tables:\n","        print(f\"\\n  ‚ö†Ô∏è  Tables that failed:\")\n","        for table in failed_tables[:10]:  # Show maximum 10\n","            print(f\"     - {table}\")\n","        if len(failed_tables) > 10:\n","            print(f\"     ... and {len(failed_tables) - 10} more\")\n","    \n","    return {\n","        \"total\": len(tables),\n","        \"success\": success_count,\n","        \"failed\": failed_count,\n","        \"skipped\": skipped_count\n","    }\n","\n","def setup_consolidated_lakehouse(target_workspace_id: str, new_lakehouse_name: str, \n","                                sources_config: Dict) -> Optional[str]:\n","    \"\"\"\n","    Creates a consolidated lakehouse with shortcuts organized by schema\n","    \"\"\"\n","    print(\"=\"*70)\n","    print(f\"Starting consolidated lakehouse setup: {new_lakehouse_name}\")\n","    print(\"=\"*70)\n","    \n","    # 1. Create new lakehouse\n","    print(f\"\\n[STEP 1] Creating target lakehouse...\")\n","    new_lakehouse_id = create_lakehouse(target_workspace_id, new_lakehouse_name)\n","    \n","    if not new_lakehouse_id:\n","        print(\"‚ùå Could not create lakehouse\")\n","        return None\n","    \n","    print(f\"‚úÖ Lakehouse created successfully\")\n","    print(f\"   ID: {new_lakehouse_id}\")\n","    print(f\"   Workspace: {target_workspace_id}\")\n","    \n","    # Wait for lakehouse to initialize completely\n","    print(\"\\n‚è≥ Waiting for lakehouse initialization...\")\n","    time.sleep(10)\n","    \n","    # Global statistics\n","    total_tables = 0\n","    total_success = 0\n","    total_failed = 0\n","    \n","    # 2. Process each source\n","    for source_name, source_config in sources_config.items():\n","        stats = process_source(\n","            target_workspace_id=target_workspace_id,\n","            target_lakehouse_id=new_lakehouse_id,\n","            source_name=source_name,\n","            source_config=source_config,\n","            refresh_mode=False\n","        )\n","        \n","        total_tables += stats[\"total\"]\n","        total_success += stats[\"success\"]\n","        total_failed += stats[\"failed\"]\n","    \n","    # Final summary\n","    print(f\"\\n{'='*70}\")\n","    print(f\"FINAL SUMMARY\")\n","    print(f\"{'='*70}\")\n","    print(f\"  Lakehouse: {new_lakehouse_name}\")\n","    print(f\"  ID: {new_lakehouse_id}\")\n","    print(f\"  Workspace: {target_workspace_id}\")\n","    print(f\"\\n  üìä Statistics:\")\n","    print(f\"     Total tables processed: {total_tables}\")\n","    print(f\"     ‚úÖ Shortcuts created: {total_success}\")\n","    print(f\"     ‚ùå Shortcuts failed: {total_failed}\")\n","    \n","    if total_success > 0:\n","        success_rate = (total_success / total_tables * 100) if total_tables > 0 else 0\n","        print(f\"     üìà Success rate: {success_rate:.1f}%\")\n","    \n","    print(f\"{'='*70}\\n\")\n","    \n","    return new_lakehouse_id\n","\n","def refresh_consolidated_lakehouse(target_workspace_id: str, target_lakehouse_id: str, \n","                                   sources_config: Dict) -> Dict:\n","    \"\"\"\n","    Refreshes shortcuts in an existing consolidated lakehouse\n","    Only creates shortcuts for new tables that don't exist yet\n","    \"\"\"\n","    print(\"=\"*70)\n","    print(f\"Refreshing consolidated lakehouse: {target_lakehouse_id}\")\n","    print(\"=\"*70)\n","    \n","    # Verify target lakehouse exists\n","    print(f\"\\nüîç Verifying target lakehouse...\")\n","    if not verify_lakehouse(target_workspace_id, target_lakehouse_id):\n","        print(\"‚ùå Cannot access target lakehouse\")\n","        return None\n","    print(f\"‚úÖ Target lakehouse accessible\")\n","    \n","    # Global statistics\n","    total_tables = 0\n","    total_success = 0\n","    total_failed = 0\n","    total_skipped = 0\n","    \n","    # Process each source in refresh mode\n","    for source_name, source_config in sources_config.items():\n","        stats = process_source(\n","            target_workspace_id=target_workspace_id,\n","            target_lakehouse_id=target_lakehouse_id,\n","            source_name=source_name,\n","            source_config=source_config,\n","            refresh_mode=True\n","        )\n","        \n","        total_tables += stats[\"total\"]\n","        total_success += stats[\"success\"]\n","        total_failed += stats[\"failed\"]\n","        total_skipped += stats[\"skipped\"]\n","    \n","    # Final summary\n","    print(f\"\\n{'='*70}\")\n","    print(f\"REFRESH SUMMARY\")\n","    print(f\"{'='*70}\")\n","    print(f\"  Lakehouse ID: {target_lakehouse_id}\")\n","    print(f\"  Workspace: {target_workspace_id}\")\n","    print(f\"\\n  üìä Statistics:\")\n","    print(f\"     Total tables found: {total_tables}\")\n","    print(f\"     ‚úÖ New shortcuts created: {total_success}\")\n","    print(f\"     ‚è≠Ô∏è  Shortcuts skipped (already exist): {total_skipped}\")\n","    print(f\"     ‚ùå Shortcuts failed: {total_failed}\")\n","    \n","    print(f\"{'='*70}\\n\")\n","    \n","    return {\n","        \"total\": total_tables,\n","        \"success\": total_success,\n","        \"failed\": total_failed,\n","        \"skipped\": total_skipped\n","    }\n","\n","def add_source_to_lakehouse(target_workspace_id: str, target_lakehouse_id: str,\n","                           source_name: str, source_config: Dict) -> Dict:\n","    \"\"\"\n","    Adds a new source to an existing consolidated lakehouse\n","    \"\"\"\n","    print(\"=\"*70)\n","    print(f\"Adding new source to lakehouse: {target_lakehouse_id}\")\n","    print(\"=\"*70)\n","    \n","    # Verify target lakehouse exists\n","    print(f\"\\nüîç Verifying target lakehouse...\")\n","    if not verify_lakehouse(target_workspace_id, target_lakehouse_id):\n","        print(\"‚ùå Cannot access target lakehouse\")\n","        return None\n","    print(f\"‚úÖ Target lakehouse accessible\")\n","    \n","    # Process the new source\n","    stats = process_source(\n","        target_workspace_id=target_workspace_id,\n","        target_lakehouse_id=target_lakehouse_id,\n","        source_name=source_name,\n","        source_config=source_config,\n","        refresh_mode=False\n","    )\n","    \n","    # Summary\n","    print(f\"\\n{'='*70}\")\n","    print(f\"ADD SOURCE SUMMARY\")\n","    print(f\"{'='*70}\")\n","    print(f\"  Source: {source_name}\")\n","    print(f\"  Schema: {source_config['schema_name']}\")\n","    print(f\"  Lakehouse ID: {target_lakehouse_id}\")\n","    print(f\"\\n  üìä Statistics:\")\n","    print(f\"     Tables processed: {stats['total']}\")\n","    print(f\"     ‚úÖ Shortcuts created: {stats['success']}\")\n","    print(f\"     ‚ùå Shortcuts failed: {stats['failed']}\")\n","    \n","    print(f\"{'='*70}\\n\")\n","    \n","    return stats"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"1bfba26f-2861-45c5-b30b-1a3ba2850f1c","normalized_state":"finished","queued_time":"2026-01-15T20:26:50.584839Z","session_start_time":null,"execution_start_time":"2026-01-15T20:26:50.5866065Z","execution_finish_time":"2026-01-15T20:26:50.957714Z","parent_msg_id":"fa0a01ba-eef4-4830-be51-3993f63f149c"},"text/plain":"StatementMeta(, 1bfba26f-2861-45c5-b30b-1a3ba2850f1c, 6, Finished, Available, Finished)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e4982984-0eaf-4af9-8629-60c917b9252e"},{"cell_type":"markdown","source":["## Use cases"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5e094cec-b97b-468b-a0ed-77524e0df02e"},{"cell_type":"markdown","source":["#### **Scenario 1: Initial Setup (First Time)**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"281940cf-bbd4-47cd-bef2-3724c8b4be62"},{"cell_type":"code","source":["#### CONFIGURATION\n","target_workspace_id= target_workspace_id\n","new_lakehouse_name= \"Consolidated_Lakehouse\"\n","\n","sources = {\n","    \"bronze\": {\n","        \"workspace_id\": \"workspace-id-bronze\",\n","        \"lakehouse_id\": \"lakehouse-id-bronze\",\n","        \"schema_name\": \"bronze_schema\",\n","        \"table_filter\": []  # Empty list = all tables, or specify: [\"table1\", \"table2\"]\n","    },\n","    \"silver\": {\n","        \"workspace_id\": \"workspace-id-silver\",\n","        \"lakehouse_id\": \"lakehouse-id-silver\", \n","        \"schema_name\": \"silver_schema\",\n","        \"table_filter\": [\"customer\", \"order\"]  # Only these tables\n","    },\n","    \"gold\": {\n","        \"workspace_id\": \"workspace-id-gold\",\n","        \"lakehouse_id\": \"lakehouse-id-gold\",\n","        \"schema_name\": \"gold_schema\",\n","        \"table_filter\": []  # All tables\n","    }\n","}\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"72b122a0-d99d-429d-8c9b-b7d46efd717f"},{"cell_type":"code","source":["new_lakehouse_id = setup_consolidated_lakehouse(\n","    target_workspace_id=target_workspace_id,\n","    new_lakehouse_name=\"Consolidated_Lakehouse\",\n","    sources_config=sources\n",")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"abe20ba0-8488-4532-a70e-01571cb4f24d"},{"cell_type":"markdown","source":["#### **Scenario 2: Refresh (Add New Tables)**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9efe9223-8269-417c-be6c-cc2a6a722b8f"},{"cell_type":"code","source":["#### CONFIGURATION\n","\n","target_workspace_id = target_workspace_id\n","target_lakehouse_id = \"your-existing-lakehouse-id\"\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"1bfba26f-2861-45c5-b30b-1a3ba2850f1c","normalized_state":"finished","queued_time":"2026-01-15T20:32:37.3191725Z","session_start_time":null,"execution_start_time":"2026-01-15T20:32:37.3203736Z","execution_finish_time":"2026-01-15T20:32:38.0644168Z","parent_msg_id":"3c57fdd8-a6d5-4aad-8003-7adcfa293957"},"text/plain":"StatementMeta(, 1bfba26f-2861-45c5-b30b-1a3ba2850f1c, 10, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n======================================================================\nOPTION 2: REFRESH LAKEHOUSE\n======================================================================\n======================================================================\nRefreshing consolidated lakehouse: your-existing-lakehouse-id\n======================================================================\n\nüîç Verifying target lakehouse...\n‚ùå Cannot access target lakehouse\n"]}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f137cf47-9f38-4ceb-b60c-a99742054c1c"},{"cell_type":"code","source":["refresh_consolidated_lakehouse(\n","    target_workspace_id=target_workspace_id,\n","    target_lakehouse_id=target_lakehouse_id,\n","    sources_config=sources\n",")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"446ecee1-bd50-417b-8f3f-ee81e3a21a4c"},{"cell_type":"markdown","source":["#### **Scenario 3: Add a New Source**\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"228d03a0-6091-46de-ac64-5597e6ef2d6b"},{"cell_type":"code","source":["#### CONFIGURATION\n","target_workspace_id = target_workspace_id\n","target_lakehouse_id = \"your-existing-lakehouse-id\"\n","source_name=\"schema_name_in_consolidated_lh\",\n","\n","# Define new source\n","new_source = {\n","    \"workspace_id\": \"workspace-id-platinum\",\n","    \"lakehouse_id\": \"lakehouse-id-platinum\",\n","    \"schema_name\": \"platinum_schema\",\n","    \"table_filter\": [\"table_1\", \"table_2\"]  # Or [] for all\n","    }"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"52c62b64-5aad-4866-801a-5fdc6161a6a2"},{"cell_type":"code","source":["add_source_to_lakehouse(\n","    target_workspace_id= target_workspace_id,\n","    target_lakehouse_id= target_lakehouse_id,\n","    source_name= source_name,\n","    source_config= new_source\n",")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4aef9c9c-a148-4966-8e9b-d27ac5f60bf7"},{"cell_type":"markdown","source":["#### **Scenario 4: Update Table Filters**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ae93b109-3b51-450a-9e9d-95caec49a194"},{"cell_type":"code","source":["#### CONFIGURATION\n","\n","target_workspace_id = target_workspace_id\n","target_lakehouse_id = \"your-existing-lakehouse-id\"\n","\n","updated_config = {\n","    \"workspace_id\": \"workspace-id-platinum\",\n","    \"lakehouse_id\": \"lakehouse-id-platinum\",\n","    \"schema_name\": \"platinum_schema\",\n","    \"table_filter\": [\"table_1\", \"table_2\", \"table_3\", \"table_4\"]  # Added 2 tables\n","}\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"11e593a7-5a53-4b3c-84c1-e4a2c5f94984"},{"cell_type":"code","source":["refresh_consolidated_lakehouse(\n","    target_workspace_id= target_workspace_id,\n","    target_lakehouse_id= target_lakehouse_id,\n","    source_name= source_name,\n","    sources_config={\"silver\": updated_silver}  # Only refresh silver\n",")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0e5eeef4-4e5d-4044-9037-43de8bdf8f8f"},{"cell_type":"markdown","source":["#### **Scenario 5: Daily refresh**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"e73555bf-a8df-404f-943e-d55e46548bb5"},{"cell_type":"code","source":["def daily_refresh_job():\n","    \"\"\"\n","    Scheduled job to refresh consolidated lakehouse\n","    Can be triggered by Fabric scheduling or orchestration\n","    \"\"\"\n","    import datetime\n","    \n","    print(f\"Starting scheduled refresh: {datetime.datetime.now()}\")\n","    \n","    # Your standard configuration\n","    sources = {\n","        \"bronze\": {...},\n","        \"silver\": {...},\n","        \"gold\": {...}\n","    }\n","    \n","    # Refresh\n","    refresh_stats = refresh_consolidated_lakehouse(\n","        target_workspace_id=target_workspace_id,\n","        target_lakehouse_id=\"your-consolidated-lakehouse-id\",\n","        sources_config=sources\n","    )\n","    \n","    # Log results\n","    if refresh_stats:\n","        print(f\"‚úÖ Refresh completed:\")\n","        print(f\"   New shortcuts: {refresh_stats['success']}\")\n","        print(f\"   Unchanged: {refresh_stats['skipped']}\")\n","        print(f\"   Failed: {refresh_stats['failed']}\")\n","        \n","        # Alert if failures\n","        if refresh_stats['failed'] > 0:\n","            print(\"‚ö†Ô∏è  WARNING: Some shortcuts failed - review logs\")\n","    \n","    return refresh_stats\n","\n","# Run the job\n","daily_refresh_job()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f8b52afe-bc21-4bb5-9f42-4b563e7d8d1c"},{"cell_type":"markdown","source":["# Documentation\n","\n","#### 1. Example Architecture\n","#### 2. Key Features\n","#### 3. Prerequisites\n","#### 4. Configuration\n","#### 5. Scenarios\n","#### 6. Good practice"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"ac430cbb-a8ac-47a6-8b95-3058b4408e97"},{"cell_type":"markdown","source":["### **1. Example Architecture**\n","\n","```\n","Consolidated Lakehouse\n","‚îú‚îÄ‚îÄ bronze_schema/\n","‚îÇ   ‚îú‚îÄ‚îÄ raw_customers (shortcut ‚Üí Bronze LH)\n","‚îÇ   ‚îú‚îÄ‚îÄ raw_orders (shortcut ‚Üí Bronze LH)\n","‚îÇ   ‚îî‚îÄ‚îÄ raw_products (shortcut ‚Üí Bronze LH)\n","‚îú‚îÄ‚îÄ silver_schema/\n","‚îÇ   ‚îú‚îÄ‚îÄ cleaned_customers (shortcut ‚Üí Silver LH)\n","‚îÇ   ‚îú‚îÄ‚îÄ cleaned_orders (shortcut ‚Üí Silver LH)\n","‚îÇ   ‚îî‚îÄ‚îÄ cleaned_products (shortcut ‚Üí Silver LH)\n","‚îî‚îÄ‚îÄ gold_schema/\n","    ‚îú‚îÄ‚îÄ dim_customer (shortcut ‚Üí Gold LH)\n","    ‚îú‚îÄ‚îÄ dim_product (shortcut ‚Üí Gold LH)\n","    ‚îî‚îÄ‚îÄ fact_sales (shortcut ‚Üí Gold LH)\n","```\n","\n","Benefits:\n","- ‚úÖ Single point of access to all data layers\n","- ‚úÖ No data duplication (shortcuts only)\n","- ‚úÖ Organized by business domains/schemas\n","- ‚úÖ Easy to maintain and refresh\n","- ‚úÖ Source lakehouses can be in different workspaces\n","\n","\n","---\n","\n","\n","### **2. Key features**\n","\n","#### 1. Initial Setup\n","Create a new consolidated lakehouse with shortcuts to all specified source lakehouses.\n","\n","#### 2. Intelligent Refresh\n","Automatically detect and create shortcuts for new tables that have been added to source lakehouses since the last run. Existing shortcuts are skipped gracefully (no errors).\n","\n","#### 3. Add New Sources\n","Dynamically add new data sources to an existing consolidated lakehouse without rebuilding everything.\n","\n","#### 4. Table Filtering\n","Control exactly which tables are included from each source:\n","- Include all tables: `\"table_filter\": []`\n","- Include specific tables: `\"table_filter\": [\"table1\", \"table2\", \"table3\"]`\n","\n","#### 5. Cross-Workspace Support\n","Source lakehouses can be located in different workspaces. The tool handles authentication and access automatically.\n","\n","#### 6. Error Handling\n","- Gracefully handles existing shortcuts (no duplicate errors)\n","- Validates lakehouse access before processing\n","- Detailed error reporting for failed operations\n","- Continues processing even if individual tables fail\n","\n","---\n","\n","### **3. Prerequisites** \n","\n","#### Required Permissions\n","Your account needs:\n","- **Read permissions** on all source workspace(s) and lakehouse(s)\n","- **Write permissions** on the target workspace where the consolidated lakehouse will be created\n","- **Contributor or Admin role** is recommended\n","\n","#### Required Libraries\n","The notebook uses:\n","- `requests` - HTTP library (pre-installed)\n","- `mssparkutils` - Fabric utilities (pre-installed)\n","- `json`, `time`, `typing` - Standard Python libraries\n","\n","---\n","\n","\n","### **4. Configuration**\n","\n","#### Step 1: Define Target Workspace\n","```python\n","# Workspace where the consolidated lakehouse will be created\n","target_workspace_id = \"your-target-workspace-id\"\n","```\n","\n","**How to find Workspace ID:**\n","1. Navigate to your workspace in Fabric\n","2. Look at the URL: `https://app.fabric.microsoft.com/groups/{workspace-id}/...`\n","3. Copy the GUID between `/groups/` and the next `/`\n","\n","#### Step 2: Configure Source Lakehouses\n","```python\n","sources = {\n","    \"bronze\": {\n","        \"workspace_id\": \"workspace-id-where-bronze-lives\",\n","        \"lakehouse_id\": \"bronze-lakehouse-id\",\n","        \"schema_name\": \"bronze_schema\",\n","        \"table_filter\": []  # Empty = all tables\n","    },\n","    \"silver\": {\n","        \"workspace_id\": \"workspace-id-where-silver-lives\",\n","        \"lakehouse_id\": \"silver-lakehouse-id\",\n","        \"schema_name\": \"silver_schema\",\n","        \"table_filter\": [\"customers\", \"orders\"]  # Only these tables\n","    },\n","    \"gold\": {\n","        \"workspace_id\": \"workspace-id-where-gold-lives\",\n","        \"lakehouse_id\": \"gold-lakehouse-id\",\n","        \"schema_name\": \"gold_schema\",\n","        \"table_filter\": []  # All tables\n","    }\n","}\n","```\n","\n","**Configuration Parameters:**\n","- `workspace_id`: Workspace GUID where the source lakehouse is located\n","- `lakehouse_id`: Lakehouse GUID of the source\n","- `schema_name`: Name for the schema in the consolidated lakehouse (appears as folder)\n","- `table_filter`: List of table names to include (empty list = all tables)\n","\n","**How to find Lakehouse ID:**\n","1. Open the lakehouse in Fabric\n","2. Look at the URL: `https://app.fabric.microsoft.com/groups/{workspace-id}/lakehouses/{lakehouse-id}`\n","3. Copy the GUID after `/lakehouses/`\n","\n","---\n","\n","\n","### **5. Scenarios**\n","\n","#### Scenario 1: Initial Setup (First Time)\n","\n","**When to use:** You're creating a consolidated lakehouse for the first time.\n","```python\n","# Define your sources (see Configuration section)\n","sources = {\n","    \"bronze\": {...},\n","    \"silver\": {...},\n","    \"gold\": {...}\n","}\n","\n","# Create the consolidated lakehouse\n","consolidated_lh_id = setup_consolidated_lakehouse(\n","    target_workspace_id=target_workspace_id,\n","    new_lakehouse_name=\"My_Consolidated_Lakehouse\",\n","    sources_config=sources\n",")\n","\n","print(f\"‚úÖ Consolidated Lakehouse created with ID: {consolidated_lh_id}\")\n","```\n","\n","**What happens:**\n","1. Creates a new lakehouse in the target workspace\n","2. Connects to each source lakehouse\n","3. Creates shortcuts for all tables (respecting filters)\n","4. Organizes shortcuts into schemas\n","5. Provides detailed statistics\n","\n","**Expected Output:**\n","```\n","======================================================================\n","Starting consolidated lakehouse setup: My_Consolidated_Lakehouse\n","======================================================================\n","\n","[STEP 1] Creating target lakehouse...\n","‚úÖ Lakehouse created successfully\n","   ID: abc-123-def-456\n","   Workspace: xyz-789-workspace\n","\n","======================================================================\n","[SOURCE] BRONZE\n","======================================================================\n","  Workspace ID: bronze-workspace-123\n","  Lakehouse ID: bronze-lh-456\n","  Target Schema: bronze_schema\n","  Table Filter: All tables\n","\n","  üîç Verifying access to source lakehouse...\n","  ‚úÖ Lakehouse accessible\n","\n","  üìã Getting table list...\n","  ‚úÖ 25 tables found\n","\n","  üîó Creating shortcuts...\n","     [  1/25] customers... ‚úÖ\n","     [  2/25] orders... ‚úÖ\n","     ...\n","\n","  üìä Summary for bronze:\n","     ‚úÖ Successfully created: 25\n","     ‚ùå Failed: 0\n","\n","[Processing continues for silver and gold...]\n","\n","======================================================================\n","FINAL SUMMARY\n","======================================================================\n","  Lakehouse: My_Consolidated_Lakehouse\n","  ID: abc-123-def-456\n","  Workspace: xyz-789-workspace\n","\n","  üìä Statistics:\n","     Total tables processed: 75\n","     ‚úÖ Shortcuts created: 75\n","     ‚ùå Shortcuts failed: 0\n","     üìà Success rate: 100.0%\n","======================================================================\n","```\n","\n","---\n","\n","#### Scenario 2: Refresh (Add New Tables)\n","\n","**When to use:** New tables have been added to your source lakehouses and you want to add them to the consolidated lakehouse.\n","```python\n","# Use the same sources configuration as initial setup\n","sources = {\n","    \"bronze\": {...},\n","    \"silver\": {...},\n","    \"gold\": {...}\n","}\n","\n","# Refresh to catch new tables\n","refresh_stats = refresh_consolidated_lakehouse(\n","    target_workspace_id=target_workspace_id,\n","    target_lakehouse_id=\"your-existing-consolidated-lakehouse-id\",\n","    sources_config=sources\n",")\n","```\n","\n","**What happens:**\n","1. Connects to each source lakehouse\n","2. Gets current list of tables\n","3. Compares with existing shortcuts\n","4. Creates shortcuts ONLY for new tables\n","5. Skips existing shortcuts (no errors)\n","\n","**Expected Output:**\n","```\n","======================================================================\n","Refreshing consolidated lakehouse: abc-123-def-456\n","======================================================================\n","\n","üîç Verifying target lakehouse...\n","‚úÖ Target lakehouse accessible\n","\n","======================================================================\n","[SOURCE] BRONZE\n","======================================================================\n","  Mode: REFRESH\n","\n","  üîó Creating shortcuts...\n","     [  1/28] customers... ‚è≠Ô∏è  (already exists)\n","     [  2/28] orders... ‚è≠Ô∏è  (already exists)\n","     [  3/28] new_table_1... ‚úÖ\n","     [  4/28] new_table_2... ‚úÖ\n","     ...\n","\n","  üìä Summary for bronze:\n","     ‚úÖ Successfully created: 3\n","     ‚è≠Ô∏è  Already exist: 25\n","     ‚ùå Failed: 0\n","\n","======================================================================\n","REFRESH SUMMARY\n","======================================================================\n","  üìä Statistics:\n","     Total tables found: 80\n","     ‚úÖ New shortcuts created: 5\n","     ‚è≠Ô∏è  Shortcuts already exist: 75\n","     ‚ùå Shortcuts failed: 0\n","======================================================================\n","```\n","\n","**Use Cases:**\n","- Daily/weekly scheduled refresh to catch new tables\n","- After ETL processes add new tables to source lakehouses\n","- Maintenance after data pipeline updates\n","\n","---\n","\n","#### Scenario 3: Add a New Source\n","\n","**When to use:** You want to add a completely new data source (e.g., adding a \"Platinum\" layer or external data) to your existing consolidated lakehouse.\n","```python\n","# Define the new source\n","platinum_source = {\n","    \"workspace_id\": \"platinum-workspace-id\",\n","    \"lakehouse_id\": \"platinum-lakehouse-id\",\n","    \"schema_name\": \"platinum_schema\",\n","    \"table_filter\": []  # All tables, or specify specific ones\n","}\n","\n","# Add to existing consolidated lakehouse\n","add_stats = add_source_to_lakehouse(\n","    target_workspace_id=target_workspace_id,\n","    target_lakehouse_id=\"your-existing-consolidated-lakehouse-id\",\n","    source_name=\"platinum\",\n","    source_config=platinum_source\n",")\n","```\n","\n","**What happens:**\n","1. Verifies access to target lakehouse\n","2. Connects to the new source lakehouse\n","3. Creates shortcuts for all tables from the new source\n","4. Organizes them in a new schema\n","\n","**Expected Output:**\n","```\n","======================================================================\n","Adding new source to lakehouse: abc-123-def-456\n","======================================================================\n","\n","üîç Verifying target lakehouse...\n","‚úÖ Target lakehouse accessible\n","\n","======================================================================\n","[SOURCE] PLATINUM\n","======================================================================\n","  Workspace ID: platinum-workspace-789\n","  Lakehouse ID: platinum-lh-012\n","  Target Schema: platinum_schema\n","  Table Filter: All tables\n","\n","  üîó Creating shortcuts...\n","     [  1/15] advanced_analytics... ‚úÖ\n","     [  2/15] ml_features... ‚úÖ\n","     ...\n","\n","======================================================================\n","ADD SOURCE SUMMARY\n","======================================================================\n","  Source: platinum\n","  Schema: platinum_schema\n","  \n","  üìä Statistics:\n","     Tables processed: 15\n","     ‚úÖ Shortcuts created: 15\n","     ‚ùå Shortcuts failed: 0\n","======================================================================\n","```\n","\n","---\n","\n","#### Scenario 4: Update Table Filters\n","\n","**When to use:** You want to add more tables from an existing source that was previously filtered.\n","\n","**Example:** You originally only included `[\"customers\", \"orders\"]` from Silver, but now you want to add `\"products\"` and `\"inventory\"`.\n","```python\n","# Original configuration\n","original_silver = {\n","    \"workspace_id\": \"silver-workspace\",\n","    \"lakehouse_id\": \"silver-lh\",\n","    \"schema_name\": \"silver_schema\",\n","    \"table_filter\": [\"customers\", \"orders\"]\n","}\n","\n","# Updated configuration - add more tables\n","updated_silver = {\n","    \"workspace_id\": \"silver-workspace\",\n","    \"lakehouse_id\": \"silver-lh\",\n","    \"schema_name\": \"silver_schema\",\n","    \"table_filter\": [\"customers\", \"orders\", \"products\", \"inventory\"]  # Added 2 tables\n","}\n","\n","# Refresh with updated configuration\n","refresh_stats = refresh_consolidated_lakehouse(\n","    target_workspace_id=target_workspace_id,\n","    target_lakehouse_id=\"your-consolidated-lakehouse-id\",\n","    sources_config={\"silver\": updated_silver}  # Only refresh silver\n",")\n","```\n","\n","**What happens:**\n","1. Processes the updated filter\n","2. Skips \"customers\" and \"orders\" (already exist)\n","3. Creates shortcuts for \"products\" and \"inventory\"\n","\n","---\n","\n","#### Scenario 5: Scheduled Maintenance\n","\n","**When to use:** You want to run a regular job (daily/weekly) to keep your consolidated lakehouse up to date.\n","```python\n","def daily_refresh_job():\n","    \"\"\"\n","    Scheduled job to refresh consolidated lakehouse\n","    Can be triggered by Fabric scheduling or orchestration\n","    \"\"\"\n","    import datetime\n","    \n","    print(f\"Starting scheduled refresh: {datetime.datetime.now()}\")\n","    \n","    # Your standard configuration\n","    sources = {\n","        \"bronze\": {...},\n","        \"silver\": {...},\n","        \"gold\": {...}\n","    }\n","    \n","    # Refresh\n","    refresh_stats = refresh_consolidated_lakehouse(\n","        target_workspace_id=target_workspace_id,\n","        target_lakehouse_id=\"your-consolidated-lakehouse-id\",\n","        sources_config=sources\n","    )\n","    \n","    # Log results\n","    if refresh_stats:\n","        print(f\"‚úÖ Refresh completed:\")\n","        print(f\"   New shortcuts: {refresh_stats['success']}\")\n","        print(f\"   Unchanged: {refresh_stats['skipped']}\")\n","        print(f\"   Failed: {refresh_stats['failed']}\")\n","        \n","        # Alert if failures\n","        if refresh_stats['failed'] > 0:\n","            print(\"‚ö†Ô∏è  WARNING: Some shortcuts failed - review logs\")\n","    \n","    return refresh_stats\n","\n","# Run the job\n","daily_refresh_job()\n","```\n","\n","**Scheduling Options:**\n","1. **Fabric Pipeline:** Create a pipeline with a Notebook activity\n","2. **Cron Job:** If using external orchestration\n","3. **Manual:** Run on-demand when needed\n","\n","---\n","\n","\n","### **6. Good practice**\n","\n","#### Keep a record of your configuration:\n","```python\n","# Configuration Documentation\n","\"\"\"\n","Consolidated Lakehouse: Analytics_Hub\n","Created: 2026-01-15\n","Owner: Data Team\n","Purpose: Unified view of medallion architecture\n","\n","Sources:\n","- Bronze: Raw data from all systems (120 tables)\n","- Silver: Cleaned and validated (85 tables, filtered)\n","- Gold: Business-ready aggregations (45 tables)\n","\n","Refresh Schedule: Daily at 2 AM UTC\n","Last Updated: 2026-01-15\n","\"\"\"\n","\n","sources = {\n","    # ... your configuration\n","}\n","```\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"030bccba-0371-4920-9a61-32c4a45728e5"},{"cell_type":"markdown","source":["# Troubleshoting"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jp-MarkdownHeadingCollapsed":true},"id":"79a249e7-f987-4a1b-90ab-130e17c3aaca"},{"cell_type":"markdown","source":["#### Common Issues and Solutions\n","\n","#### **Issue 1: \"Cannot access lakehouse\"**\n","```\n","‚ùå Cannot access lakehouse bronze\n","   Check permissions and verify the ID is correct\n","```\n","\n","**Solutions:**\n","1. Verify the lakehouse ID is correct\n","   - Open lakehouse in browser\n","   - Check URL for correct GUID\n","2. Check workspace permissions\n","   - You need at least Read access\n","3. Verify the lakehouse hasn't been deleted or renamed\n","\n","**How to verify:**\n","```python\n","# Test lakehouse access manually\n","test_url = f\"{base_url}/workspaces/{workspace_id}/lakehouses/{lakehouse_id}\"\n","response = requests.get(test_url, headers=headers)\n","print(f\"Status: {response.status_code}\")\n","print(f\"Response: {response.text}\")\n","```\n","\n","---\n","\n","#### **Issue 2: \"No tables found\"**\n","```\n","‚ö†Ô∏è  No tables found in bronze\n","```\n","\n","**Solutions:**\n","1. Check if source lakehouse actually has tables\n","   - Open lakehouse in Fabric UI\n","   - Verify tables exist in Tables section\n","2. Tables might be in Files section (not supported)\n","   - Shortcuts only work with Delta tables\n","3. Check if tables are still loading\n","\n","---\n","\n","#### **Issue 3: Filtered tables not found**\n","```\n","‚ö†Ô∏è  No tables match the filter criteria\n","```\n","\n","**Solutions:**\n","1. Check spelling of table names in filter\n","2. Table names are case-sensitive\n","3. Remove filter temporarily to see all available tables:\n","```python\n","   # Temporarily set filter to empty to see all tables\n","   \"table_filter\": []\n","```\n","\n","---\n","\n","#### **Issue 4: Some shortcuts fail**\n","```\n","‚ùå Shortcuts failed: 3\n","```\n","\n","**Solutions:**\n","1. Check the detailed error messages in output\n","2. Common causes:\n","   - Source table was deleted\n","   - Permission changes\n","   - Network issues\n","3. Run refresh again - transient errors often resolve\n","4. Check specific table:\n","```python\n","   # Debug specific table\n","   tables = get_lakehouse_tables(workspace_id, lakehouse_id)\n","   print([t['name'] for t in tables])\n","```\n","\n","---\n","\n","#### **Issue 5: Rate limiting errors**\n","```\n","Error: 429 - Too Many Requests\n","```\n","\n","**Solutions:**\n","1. The tool includes automatic delays (`time.sleep(0.5)`)\n","2. If still occurring, increase delay:\n","```python\n","   # In process_source function, increase sleep time\n","   time.sleep(1.0)  # Instead of 0.5\n","```\n","3. Process sources in smaller batches\n","\n","---\n","\n","#### Issue 6: **Authentication errors**\n","```\n","Error: 401 - Unauthorized\n","```\n","\n","**Solutions:**\n","1. Token may have expired - rerun the notebook\n","2. Verify you're using the correct authentication:\n","```python\n","   token = mssparkutils.credentials.getToken(\"pbi\")\n","```\n","3. Check if workspace/lakehouse access was revoked\n","\n","---\n","\n","### Debug Mode\n","\n","Enable detailed logging for troubleshooting:\n","```python\n","# Add at the top of your notebook\n","DEBUG = True\n","\n","# Modify functions to include debug output\n","if DEBUG:\n","    print(f\"DEBUG: Attempting to create shortcut\")\n","    print(f\"  Target: {target_lakehouse_id}\")\n","    print(f\"  Source: {source_lakehouse_id}\")\n","    print(f\"  Table: {table_name}\")\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9d6ab2b5-d103-4a01-bc61-522933785884"},{"cell_type":"markdown","source":["---\n","# Getting Help\n","\n","**Useful Links:**\n","- [Microsoft Fabric Documentation](https://learn.microsoft.com/fabric/)\n","- [OneLake Shortcuts Documentation](https://learn.microsoft.com/fabric/onelake/onelake-shortcuts)\n","- [Fabric REST API Reference](https://learn.microsoft.com/rest/api/fabric/)\n","\n","---\n","\n","## Version History\n","\n","| Version | Date | Changes |\n","|---------|------|---------|\n","| 1.0 | 2026-01-15 | Initial release |\n","\n","---\n","\n","## Support and Feedback\n","\n","For questions, issues, or suggestions:\n","- Contact: eneko.egiguren.gomez@gmail.com\n","- Linkedin: https://www.linkedin.com/in/enekoegiguren/\n","---\n","\n","**Remember:** This tool creates shortcuts, not copies. Changes in source lakehouses are immediately reflected in the consolidated lakehouse. There is no data duplication, which keeps storage costs low but means source lakehouses must remain accessible."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"120d4ed1-2415-40d2-8330-1a697722a8e4"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}